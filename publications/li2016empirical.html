<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta name="google-site-verification"
      content="XmgClnbEKziAyxnX-L7KcLkvKpPrGYHE2e0AWyoi2oE">
    <title>An Empirical Study of Skip-Gram Features and Regularization
      for Learning on Sentiment Analysis</title>
    <!-- Metadata -->
    <!-- Google Scholar Meta Data -->
    <meta name="citation_publisher" content="Springer International
      Publishing">
    <meta name="citation_title" content="An Empirical Study of Skip-Gram
      Features and Regularization for Learning on Sentiment Analysis">
    <meta name="citation_firstpage" content="72">
    <meta name="citation_lastpage" content="87">
    <meta name="citation_doi" content="10.1007/978-3-319-30671-1_6">
    <meta name="citation_language" content="en">
    <meta name="citation_pdf_url"
content="http://link.springer.com/content/pdf/10.1007%2F978-3-319-30671-1_6.pdf">
    <meta name="citation_pdf_url"
      content="http://www.chengli.io/publications/li2016empirical.pdf">
    <meta name="citation_author" content="Cheng Li">
    <meta name="citation_author_institution" content="Northeastern
      University">
    <meta name="citation_author_email" content="chengli@ccs.neu.edu">
    <meta name="citation_author" content="Bingyu Wang">
    <meta name="citation_author_institution" content="Northeastern
      University">
    <meta name="citation_author" content="Virgil Pavlu">
    <meta name="citation_author_institution" content="Northeastern
      University">
    <meta name="citation_author" content="Javed A. Aslam">
    <meta name="citation_author_institution" content="Northeastern
      University">
    <meta name="citation_inbook_title" content="Advances in Information
      Retrieval">
    <meta name="citation_publication_date" content="2016/03/20">
    <meta name="citation_conference_series_id" content="springer/ecir">
    <meta name="citation_conference_title" content="European Conference
      on Information Retrieval">
    <meta name="citation_conference_sequence_num" content="38">
    <meta name="citation_conference_abbrev" content="ECIR">
  </head>
  <body>
    <h2>
      <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    </h2>
    <h1 xmlns="http://www.w3.org/1999/xhtml" class="ChapterTitle"
      lang="en">An Empirical Study of Skip-Gram Features and
      Regularization for Learning on Sentiment Analysis</h1>
    Cheng Li, Bingyu Wang, Virgil Pavlu, Javed A. Aslam<i><b><br>
        <br>
      </b></i>Proceedings of the 38th European Conference on Information
    Retrieval (ECIR), Padova, Italy, 2016.
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <div class="KeywordGroup" lang="en">
      <h2 class="Heading">Keywords</h2>
      <span class="Keyword">Sentiment analysis</span>;&nbsp;&nbsp;&nbsp;
      <span class="Keyword">Skip-grams</span>;&nbsp;&nbsp;&nbsp; <span
        class="Keyword">Feature selection</span>;&nbsp;&nbsp;&nbsp; <span
        class="Keyword">Regularization</span> </div>
    <br>
    <h2>Abstract</h2>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <p id="Par1" class="Para">The problem of deciding the overall
      sentiment of a user review is usually treated as a text
      classification problem. The simplest machine learning setup for
      text classification uses a unigram bag-of-words feature
      representation of documents, and this has been shown to work well
      for a number of tasks such as spam detection and topic
      classification. However, the problem of sentiment analysis is more
      complex and not as easily captured with unigram (single-word)
      features. Bigram and trigram features capture certain local
      context and short distance negations—thus outperforming unigram
      bag-of-words features for sentiment analysis. But higher order <em
        class="EmphasisTypeItalic ">n</em>-gram features are often
      overly specific and sparse, so they increase model complexity and
      do not generalize well.</p>
    <p id="Par2" class="Para">In this paper, we perform an empirical
      study of <em class="EmphasisTypeItalic ">skip-gram</em> features
      for large scale sentiment analysis. We demonstrate that skip-grams
      can be used to improve sentiment analysis performance in a
      model-efficient and scalable manner via regularized logistic
      regression. The feature sparsity problem associated with higher
      order <em class="EmphasisTypeItalic ">n</em>-grams can be
      alleviated by grouping similar <em class="EmphasisTypeItalic ">n</em>-grams

      into a single skip-gram: For example, “waste time” could match the
      <em class="EmphasisTypeItalic ">n</em>-gram variants “waste of
      time”, “waste my time”, “waste more time”, “waste too much time”,
      “waste a lot of time”, and so on. To promote model-efficiency and
      prevent overfitting, we demonstrate the utility of logistic
      regression incorporating both L1 regularization (for feature
      selection) and L2 regularization (for weight distribution).</p>
    <h2>Downloads</h2>
    <div id="extras">
      <ul>
        <li><a href="li2016empirical.pdf">Full Paper</a></li>
        <li><a href="li2016empirical.bib">BibTex</a><br>
        </li>
        <li><a href="li2016empirical_slides.pdf">Slides</a><br>
        </li>
      </ul>
    </div>
    <!-- extras -->
  </body>
</html>
