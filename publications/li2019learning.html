<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta name="google-site-verification"
      content="XmgClnbEKziAyxnX-L7KcLkvKpPrGYHE2e0AWyoi2oE">
    <!-- Metadata -->
    <!-- Google Scholar Meta Data -->
    <meta name="citation_title" content="Learning to Calibrate and
      Rerank Multi-label Predictions">
    <meta name="citation_publisher" content="Springer, Cham">
    <meta name="citation_doi" content="10.1007/978-3-030-46133-1_14">
    <meta name="citation_language" content="en">
    <meta name="citation_firstpage" content="220">
    <meta name="citation_lastpage" content="236">
    <meta name="citation_author" content="Cheng Li">
    <meta name="citation_author_institution" content="Northeastern
      University">
    <meta name="citation_author_email" content="chengli@ccs.neu.edu">
    <meta name="citation_author" content="Virgil Pavlu">
    <meta name="citation_author_institution" content="Northeastern
      University">
    <meta name="citation_author" content="Javed Aslam">
    <meta name="citation_author_institution" content="Northeastern
      University">
    <meta name="citation_author" content="Bingyu Wang">
    <meta name="citation_author_institution" content="Northeastern
      University">
    <meta name="citation_author" content="Kechen Qin">
    <meta name="citation_author_institution" content="Northeastern
      University">
    <meta name="citation_inbook_title" content="Machine Learning and
      Knowledge Discovery in Databases">
    <meta name="citation_publication_date" content="2019/09/16">
    <meta name="citation_conference_series_id" content="springer/ecml">
    <meta name="citation_conference_title" content="Joint European
      Conference on Machine Learning and Knowledge Discovery in
      Databases">
    <meta name="citation_conference_abbrev" content="ECML PKDD">
    <meta name="citation_pdf_url"
      content="http://www.chengli.io/publications/li2019learning.pdf">
    <title>Learning to Calibrate and Rerank Multi-label Predictions</title>
  </head>
  <body>
    <h1>Learning to Calibrate and Rerank Multi-label Predictions<br>
    </h1>
    <p>
      <meta http-equiv="content-type" content="text/html; charset=UTF-8">
      <span class="authors"><span>Cheng Li, Virgil Pavlu, Javed Aslam</span>,
      </span><span class="authors"><span>Bingyu Wang, and Kechen Qin</span></span>
      <meta http-equiv="content-type" content="text/html; charset=UTF-8">
      <br>
      Joint European Conference on Machine Learning and Knowledge
      Discovery in Databases (ECML PKDD), Würzburg, Germany, 2019.<br>
    </p>
    <h2>Downloads</h2>
    <p>[<a href="li2019learning.pdf"><b>Paper</b></a>] [<a
        href="li2019learning_supplementary.pdf"><b>Supplementary
          Material</b></a>] [<a href="li2019learning_slides.pdf"><b>Slides</b></a>]
      [<a href="li2019learning_poster.pdf"><b>Poster</b></a>] [<a
        href="https://github.com/cheng-li/pyramid"><b>Code</b></a>]<br>
    </p>
    <p>An extended version of this work is presented in Chapter 4 of <a
href="Reduction_Methods_for_Multi-Label_Classification_Cheng_Li.pdf">my
        Phd thesis</a>.<br>
    </p>
    <h2>Abstract</h2>
    <p>A multi-label classifier assigns a set of labels to each data
      object. A natural requirement in many end-use applications is that
      the classifier also provides a well-calibrated confidence
      (probability) to indicate the likelihood of the predicted set
      being correct; for example, an application may automate
      high-confidence predictions while manually verifying
      low-confidence predictions. The simplest multi-label classifier,
      called Binary Relevance (BR), applies one binary classifier to
      each label independently and takes the product of the individual
      label probabilities as the overall label-set probability
      (confidence). Despite its many known drawbacks, such as generating
      suboptimal predictions and poorly calibrated confidence scores, BR
      is widely used in practice due to its speed and simplicity. We
      seek in this work to improve both BR’s confidence estimation and
      prediction through a post calibration and reranking procedure. We
      take the BR predicted set of labels and its product score as
      features, extract more features from the prediction itself to
      capture label constraints, and apply Gradient Boosted Trees (GB)
      as a calibrator to map these features into a calibrated confidence
      score. GB not only produces well-calibrated scores (aligned with
      accuracy and sharp), but also models label interactions,
      correcting a critical flaw in BR. We further show that reranking
      label sets by the new calibrated confidence makes accurate set
      predictions on par with state-of-the-art multi-label
      classifiers—yet calibrated, simpler, and faster.<br>
    </p>
    <!--?xml version="1.0" encoding="UTF-8" standalone="no"?-->
    <title></title>
    <!-- extras -->
  </body>
</html>
